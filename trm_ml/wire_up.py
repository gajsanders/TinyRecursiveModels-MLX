#!/usr/bin/env python3
"""
Wire up module for Tiny Recursive Model (TRM)

This module connects all components - TRM model, data loader, training, 
evaluation, and logging - into a single pipeline that can run on sample data.
"""

import os
import sys
from typing import Optional, Dict, Any

def load_modules():
    """Load all required modules, handling the local mlx directory conflict."""
    # Insert the installed packages path first
    sys.path.insert(0, '/Users/enceladus/Library/Python/3.9/lib/python/site-packages')
    
    # Import the MLX library
    import mlx.core as mx
    
    # Now use importlib to import the local modules directly from file
    import importlib.util
    
    # Import local modules using importlib to avoid path conflicts
    project_root = os.path.dirname(os.path.dirname(__file__))
    
    # Import model_trm
    model_trm_path = os.path.join(project_root, 'trm_ml', 'model_trm.py')
    spec = importlib.util.spec_from_file_location("model_trm", model_trm_path)
    model_trm = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(model_trm)
    TRM = model_trm.TRM
    
    # Import training
    training_path = os.path.join(project_root, 'trm_ml', 'training.py')
    spec = importlib.util.spec_from_file_location("training", training_path)
    training = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(training)
    train_one_epoch = training.train_one_epoch
    
    # Import evaluation
    evaluation_path = os.path.join(project_root, 'trm_ml', 'evaluation.py')
    spec = importlib.util.spec_from_file_location("evaluation", evaluation_path)
    evaluation = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(evaluation)
    run_evaluation = evaluation.run_evaluation
    
    # Import data_utils
    data_utils_path = os.path.join(project_root, 'trm_ml', 'data_utils.py')
    spec = importlib.util.spec_from_file_location("data_utils", data_utils_path)
    data_utils = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(data_utils)
    create_dataloader = data_utils.create_dataloader
    
    # Import device
    device_path = os.path.join(project_root, 'trm_ml', 'device.py')
    spec = importlib.util.spec_from_file_location("device", device_path)
    device = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(device)
    get_device = device.get_device
    
    # Import logging_utils
    logging_path = os.path.join(project_root, 'trm_ml', 'utils', 'logging_utils.py')
    spec = importlib.util.spec_from_file_location("logging_utils", logging_path)
    logging_utils = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(logging_utils)
    log_msg = logging_utils.log_msg
    
    return mx, TRM, train_one_epoch, run_evaluation, create_dataloader, get_device, log_msg

# Load all modules
mx, TRM, train_one_epoch, run_evaluation, create_dataloader, get_device, log_msg = load_modules()


def run_full_pipeline(
    input_dim: int = 128,
    latent_dim: int = 256, 
    output_dim: int = 64,
    epochs: int = 3,
    batch_size: int = 16,
    data_path: Optional[str] = None,
    use_sample_data: bool = True
) -> Dict[str, Any]:
    """
    Run the full TRM pipeline: initialize model, load data, train, and evaluate.
    
    Args:
        input_dim: Dimension of input features
        latent_dim: Dimension of latent state
        output_dim: Dimension of output
        epochs: Number of training epochs
        batch_size: Batch size for training
        data_path: Path to dataset (if None, uses sample data)
        use_sample_data: Whether to use sample data instead of loading from path
        
    Returns:
        Dictionary containing results from training and evaluation
    """
    log_msg("Starting full TRM pipeline", level="INFO")
    
    # Determine device
    device = get_device()
    log_msg(f"Using device: {device}", level="INFO")
    
    # Initialize model
    log_msg(f"Initializing TRM model with input_dim={input_dim}, latent_dim={latent_dim}, output_dim={output_dim}", level="INFO")
    model = TRM(
        input_dim=input_dim,
        latent_dim=latent_dim,
        output_dim=output_dim
    )
    log_msg("Model initialized successfully", level="INFO")
    
    # Create sample data
    log_msg("Creating sample data for pipeline", level="INFO")
    import numpy as np
    sample_input = np.random.rand(100, input_dim).astype(np.float32)
    sample_target = np.random.rand(100, output_dim).astype(np.float32)
    
    # Split data into train and eval sets
    split_idx = 80  # 80% for training, 20% for evaluation
    train_input = sample_input[:split_idx]
    train_target = sample_target[:split_idx]
    eval_input = sample_input[split_idx:]
    eval_target = sample_target[split_idx:]
    
    # Since there seems to be an issue with the data loader converting types properly,
    # Let's create data in the format expected by the training/evaluation functions
    # We'll manually create the batched data in proper format
    train_batches = []
    for i in range(0, len(train_input), batch_size):
        batch_x = mx.array(train_input[i:i+batch_size])
        batch_y = mx.array(train_target[i:i+batch_size])
        train_batches.append((batch_x, batch_y))
    
    eval_batches = []
    for i in range(0, len(eval_input), batch_size):
        batch_x = mx.array(eval_input[i:i+batch_size])
        batch_y = mx.array(eval_target[i:i+batch_size])
        eval_batches.append((batch_x, batch_y))
    
    log_msg(f"Created batched data - train batches: {len(train_batches)}, eval batches: {len(eval_batches)}", level="INFO")
    
    # Training loop
    log_msg(f"Starting training for {epochs} epochs", level="INFO")
    training_results = []
    
    for epoch in range(epochs):
        log_msg(f"Epoch {epoch + 1}/{epochs}", level="INFO")
        
        try:
            avg_loss = train_one_epoch(model, train_batches, optimizer=None)
            training_results.append({
                'epoch': epoch + 1,
                'loss': avg_loss,
                'status': 'completed'
            })
            log_msg(f"Epoch {epoch + 1} completed with loss: {avg_loss:.4f}", level="INFO")
        except Exception as e:
            log_msg(f"Error during epoch {epoch + 1}: {str(e)}", level="ERROR")
            training_results.append({
                'epoch': epoch + 1,
                'loss': float('inf'),
                'status': 'failed',
                'error': str(e)
            })
    
    log_msg("Training completed", level="INFO")
    
    # Run evaluation
    log_msg("Starting evaluation", level="INFO")
    try:
        eval_result = run_evaluation(model, eval_batches)
        log_msg(f"Evaluation completed with mean output: {eval_result}", level="INFO")
    except Exception as e:
        log_msg(f"Evaluation failed: {str(e)}", level="ERROR")
        eval_result = {'status': 'failed', 'error': str(e)}
    
    # Compile results
    results = {
        'model_config': {
            'input_dim': input_dim,
            'latent_dim': latent_dim,
            'output_dim': output_dim
        },
        'training_results': training_results,
        'evaluation_result': eval_result,
        'epochs_run': epochs,
        'batch_size': batch_size,
        'device': device,
        'data_info': {
            'train_samples': len(train_input),
            'eval_samples': len(eval_input),
            'train_batches': len(train_batches),
            'eval_batches': len(eval_batches)
        }
    }
    
    log_msg("Full pipeline completed successfully", level="INFO")
    
    return results


def main():
    """Main entry point for running the full pipeline."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Run full TRM pipeline")
    parser.add_argument("--input-dim", type=int, default=128, help="Input dimension")
    parser.add_argument("--latent-dim", type=int, default=256, help="Latent dimension")
    parser.add_argument("--output-dim", type=int, default=64, help="Output dimension")
    parser.add_argument("--epochs", type=int, default=3, help="Number of epochs")
    parser.add_argument("--batch-size", type=int, default=16, help="Batch size")
    parser.add_argument("--data-path", type=str, help="Path to data (optional)")
    
    args = parser.parse_args()
    
    results = run_full_pipeline(
        input_dim=args.input_dim,
        latent_dim=args.latent_dim,
        output_dim=args.output_dim,
        epochs=args.epochs,
        batch_size=args.batch_size,
        data_path=args.data_path
    )
    
    print("Pipeline Results:")
    print(f"  Model Config: {results['model_config']}")
    print(f"  Training Results: {results['training_results']}")
    print(f"  Evaluation Result: {results['evaluation_result']}")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())